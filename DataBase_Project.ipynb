{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Database Management Project: <br> Recommender System using ALS for implicit Feedback </center>\n",
    "### <center> Tommy Tran, Thomas de Mareuil, Constantin Vodé - March 2020 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is based on the paper \"Fast Matrix Factorization for Online Recommendation with Implicit Feedback\" by He Xiangnan _et al._ , School of Computing, National University of Singapore, published at SIGIR '16, July 17-21, 2016, Pisa, Italy, and available through this [link](https://www.comp.nus.edu.sg/~xiangnan/papers/sigir16-eals-cm.pdf).\n",
    "\n",
    "The data we use in this project is a dataset recommended in the paper, comprising 78.930 reviews for Cell phones & Accesories on Amazon, collected by Stanford's Jure Leskovec, PhD, and available through this [link](http://snap.stanford.edu/data/web-Amazon-links.html).\n",
    "\n",
    "We start by parsing the original dataset and loading it in Spark to explore it. Then we implement the regular ALS method for matrix factorization and the more efficient eALS method presented in the paper. In these steps, we implement algortihms in Spark \"from scratch\", translating some Java code lines that can be found in the paper. Last, in the final section we implement ALS using PySpark's existing ALS library, and we test it on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#-Database-Management-Project:--Recommender-System-using-ALS-for-implicit-Feedback-\" data-toc-modified-id=\"-Database-Management-Project:--Recommender-System-using-ALS-for-implicit-Feedback--1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span><center> Database Management Project: <br> Recommender System using ALS for implicit Feedback </center></a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#-Tommy-Tran,-Thomas-de-Mareuil,-Constantin-Vodé---March-2020-\" data-toc-modified-id=\"-Tommy-Tran,-Thomas-de-Mareuil,-Constantin-Vodé---March-2020--1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span><center> Tommy Tran, Thomas de Mareuil, Constantin Vodé - March 2020 </center></a></span></li></ul></li><li><span><a href=\"#Parsing,-loading-and-exploring-the-data-in-Spark\" data-toc-modified-id=\"Parsing,-loading-and-exploring-the-data-in-Spark-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Parsing, loading and exploring the data in Spark</a></span><ul class=\"toc-item\"><li><span><a href=\"#Parsing-the-Data\" data-toc-modified-id=\"Parsing-the-Data-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Parsing the Data</a></span></li><li><span><a href=\"#Loading-the-data-in-Spark\" data-toc-modified-id=\"Loading-the-data-in-Spark-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Loading the data in Spark</a></span></li><li><span><a href=\"#Data-exploration-with-Spark\" data-toc-modified-id=\"Data-exploration-with-Spark-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Data exploration with Spark</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-are-the-possible-ratings?\" data-toc-modified-id=\"What-are-the-possible-ratings?-1.1.3.1\"><span class=\"toc-item-num\">1.1.3.1&nbsp;&nbsp;</span>What are the possible ratings?</a></span></li><li><span><a href=\"#What-are-the-minimum-number-of-ratings-per-user-and-minimum-number-of-ratings-per-product-(for-rated-products)?\" data-toc-modified-id=\"What-are-the-minimum-number-of-ratings-per-user-and-minimum-number-of-ratings-per-product-(for-rated-products)?-1.1.3.2\"><span class=\"toc-item-num\">1.1.3.2&nbsp;&nbsp;</span>What are the minimum number of ratings per user and minimum number of ratings per product (for rated products)?</a></span></li><li><span><a href=\"#What-is-the-total-number-of-users-in-the-data-set?\" data-toc-modified-id=\"What-is-the-total-number-of-users-in-the-data-set?-1.1.3.3\"><span class=\"toc-item-num\">1.1.3.3&nbsp;&nbsp;</span>What is the total number of users in the data set?</a></span></li><li><span><a href=\"#What-is-the-total-number-of-products-in-the-data-set?\" data-toc-modified-id=\"What-is-the-total-number-of-products-in-the-data-set?-1.1.3.4\"><span class=\"toc-item-num\">1.1.3.4&nbsp;&nbsp;</span>What is the total number of products in the data set?</a></span></li><li><span><a href=\"#What-are-the-unrated-products?\" data-toc-modified-id=\"What-are-the-unrated-products?-1.1.3.5\"><span class=\"toc-item-num\">1.1.3.5&nbsp;&nbsp;</span>What are the unrated products?</a></span></li><li><span><a href=\"#Extracting-relevant-rating-data-as-an-RDD-for-further-analysis\" data-toc-modified-id=\"Extracting-relevant-rating-data-as-an-RDD-for-further-analysis-1.1.3.6\"><span class=\"toc-item-num\">1.1.3.6&nbsp;&nbsp;</span>Extracting relevant rating data as an RDD for further analysis</a></span></li></ul></li></ul></li><li><span><a href=\"#Our-implemention-of-the-ALS-matrix-factorization-algorithm-in-Spark\" data-toc-modified-id=\"Our-implemention-of-the-ALS-matrix-factorization-algorithm-in-Spark-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Our implemention of the ALS matrix factorization algorithm in Spark</a></span></li><li><span><a href=\"#Our-implemention-of-the-eALS-algorithm-for-fast-matrix-factorization-in-Spark\" data-toc-modified-id=\"Our-implemention-of-the-eALS-algorithm-for-fast-matrix-factorization-in-Spark-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Our implemention of the eALS algorithm for fast matrix factorization in Spark</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Reconstruct-ratings-from-reconstructed-rating-matrix-table-to-compare-with-predicted-ratings\" data-toc-modified-id=\"Reconstruct-ratings-from-reconstructed-rating-matrix-table-to-compare-with-predicted-ratings-1.3.0.1\"><span class=\"toc-item-num\">1.3.0.1&nbsp;&nbsp;</span>Reconstruct ratings from reconstructed rating matrix table to compare with predicted ratings</a></span></li></ul></li></ul></li><li><span><a href=\"#ALS-implementation-using-the-existing-PySpark-library\" data-toc-modified-id=\"ALS-implementation-using-the-existing-PySpark-library-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>ALS implementation using the existing PySpark library</a></span><ul class=\"toc-item\"><li><span><a href=\"#Recommender-system-with-existing-PySpark-ALS\" data-toc-modified-id=\"Recommender-system-with-existing-PySpark-ALS-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>Recommender system with existing PySpark ALS</a></span></li><li><span><a href=\"#ALS-model-evaluation-and-selection-(grid-search)\" data-toc-modified-id=\"ALS-model-evaluation-and-selection-(grid-search)-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>ALS model evaluation and selection (grid search)</a></span></li><li><span><a href=\"#ALS-model-learning-curve\" data-toc-modified-id=\"ALS-model-learning-curve-1.4.3\"><span class=\"toc-item-num\">1.4.3&nbsp;&nbsp;</span>ALS model learning curve</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Thomas/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# spark imports\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import UserDefinedFunction, explode, desc\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# data science imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import matrix\n",
    "from numpy.random import rand\n",
    "from sklearn import preprocessing\n",
    "import math\n",
    "from math import floor\n",
    "\n",
    "# visualization imports\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# other imports\n",
    "import sys\n",
    "import time\n",
    "#from __future__ import print_function\n",
    "import gzip\n",
    "from ast import literal_eval\n",
    "import json\n",
    "import simplejson\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing, loading and exploring the data in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(filename):\n",
    "    \"\"\"\n",
    "    Function to parse the \"Cell Phones & Accessories Ratings\" dataset (.txt format)\n",
    "    \"\"\"\n",
    "    f = open(filename, 'r')\n",
    "    entry = {}\n",
    "    for l in f:\n",
    "        l = l.strip()\n",
    "        colonPos = l.find(':')\n",
    "        if colonPos == -1:\n",
    "            yield entry\n",
    "            entry = {}\n",
    "            continue\n",
    "        eName = l[:colonPos]\n",
    "        rest = l[colonPos+2:]\n",
    "        entry[eName] = rest\n",
    "    yield entry\n",
    "\n",
    "\n",
    "# Parsing the data\n",
    "\n",
    "for e in parse(\"Cell_Phones_&_Accessories.txt\"):\n",
    "    a = simplejson.dumps(e)\n",
    "    a = literal_eval(a)\n",
    "    df = pd.DataFrame(a, index=[1,])\n",
    "    df = df.drop(index=1)\n",
    "    break;\n",
    "\n",
    "i=0\n",
    "for e in parse(\"Cell_Phones_&_Accessories.txt\"):\n",
    "    i+=1\n",
    "    b = simplejson.dumps(e)\n",
    "    b = literal_eval(b)\n",
    "\n",
    "    b = pd.DataFrame(b, index=[1,])\n",
    "    df = df.append(b, ignore_index=True)\n",
    "    if i==1000:\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding products Ids (label encoding)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['product/productId'])\n",
    "le.classes_\n",
    "df['product/productId'] = le.transform(df['product/productId'])\n",
    "\n",
    "# Encoding users Ids (label encoding)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['review/userId'])\n",
    "le.classes_\n",
    "df['review/userId'] = le.transform(df['review/userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product/productId</th>\n",
       "      <th>product/title</th>\n",
       "      <th>product/price</th>\n",
       "      <th>review/userId</th>\n",
       "      <th>review/profileName</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>Mobile Action MA730 Handset Manager - Bluetoot...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>202</td>\n",
       "      <td>A. Igoe</td>\n",
       "      <td>0/0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1233360000</td>\n",
       "      <td>Don't buy!</td>\n",
       "      <td>First of all, the company took my money and se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76</td>\n",
       "      <td>Mobile Action MA730 Handset Manager - Bluetoot...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>734</td>\n",
       "      <td>Steven Martz</td>\n",
       "      <td>0/0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1191456000</td>\n",
       "      <td>Mobile Action Bluetooth Mobile Phone Tool Soft...</td>\n",
       "      <td>Great product- tried others and this is a ten ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>Mobile Action MA730 Handset Manager - Bluetoot...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>398</td>\n",
       "      <td>Daniel M. Johnson \"rocknbluesharp\"</td>\n",
       "      <td>0/0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1186704000</td>\n",
       "      <td>good</td>\n",
       "      <td>works real good....a little hard to set up...w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>USB Data Cable for Sony-Ericsson Z600, Z500, Z...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>316</td>\n",
       "      <td>E. Owens</td>\n",
       "      <td>4/5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1146182400</td>\n",
       "      <td>No instructions included...</td>\n",
       "      <td>The price was right for this cable ($11.95+$4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>USB Data Cable for Sony-Ericsson Z600, Z500, Z...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>857</td>\n",
       "      <td>Isaac Salas \"=CRBF=gB^link\"</td>\n",
       "      <td>0/0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1173657600</td>\n",
       "      <td>NOT A DATA CABLE</td>\n",
       "      <td>this is NOT a DATA CABLE this is only a USB ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product/productId                                      product/title  \\\n",
       "0                 76  Mobile Action MA730 Handset Manager - Bluetoot...   \n",
       "1                 76  Mobile Action MA730 Handset Manager - Bluetoot...   \n",
       "2                 76  Mobile Action MA730 Handset Manager - Bluetoot...   \n",
       "3                 43  USB Data Cable for Sony-Ericsson Z600, Z500, Z...   \n",
       "4                 43  USB Data Cable for Sony-Ericsson Z600, Z500, Z...   \n",
       "\n",
       "  product/price  review/userId                  review/profileName  \\\n",
       "0       unknown            202                             A. Igoe   \n",
       "1       unknown            734                        Steven Martz   \n",
       "2       unknown            398  Daniel M. Johnson \"rocknbluesharp\"   \n",
       "3       unknown            316                            E. Owens   \n",
       "4       unknown            857         Isaac Salas \"=CRBF=gB^link\"   \n",
       "\n",
       "  review/helpfulness  review/score  review/time  \\\n",
       "0                0/0           1.0   1233360000   \n",
       "1                0/0           5.0   1191456000   \n",
       "2                0/0           4.0   1186704000   \n",
       "3                4/5           4.0   1146182400   \n",
       "4                0/0           1.0   1173657600   \n",
       "\n",
       "                                      review/summary  \\\n",
       "0                                         Don't buy!   \n",
       "1  Mobile Action Bluetooth Mobile Phone Tool Soft...   \n",
       "2                                               good   \n",
       "3                        No instructions included...   \n",
       "4                                   NOT A DATA CABLE   \n",
       "\n",
       "                                         review/text  \n",
       "0  First of all, the company took my money and se...  \n",
       "1  Great product- tried others and this is a ten ...  \n",
       "2  works real good....a little hard to set up...w...  \n",
       "3  The price was right for this cable ($11.95+$4....  \n",
       "4  this is NOT a DATA CABLE this is only a USB ch...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving as .csv\n",
    "\n",
    "df.to_csv('ratings.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('ratings.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a useable dataset, we can load it and explore it in Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark config\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"product recommendations\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"96g\") \\\n",
    "    .config(\"spark.driver.memory\", \"96g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.master\", \"local[12]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# get spark context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------+-------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|product/productId|       product/title|product/price|review/userId|  review/profileName|review/helpfulness|review/score|review/time|      review/summary|         review/text|\n",
      "+-----------------+--------------------+-------------+-------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|               76|Mobile Action MA7...|      unknown|          202|             A. Igoe|               0/0|         1.0| 1233360000|          Don't buy!|First of all, the...|\n",
      "|               76|Mobile Action MA7...|      unknown|          734|        Steven Martz|               0/0|         5.0| 1191456000|Mobile Action Blu...|Great product- tr...|\n",
      "|               76|Mobile Action MA7...|      unknown|          398|\"Daniel M. Johnso...|               0/0|         4.0| 1186704000|                good|works real good.....|\n",
      "|               43|USB Data Cable fo...|      unknown|          316|            E. Owens|               4/5|         4.0| 1146182400|No instructions i...|The price was rig...|\n",
      "|               43|USB Data Cable fo...|      unknown|          857|\"Isaac Salas \"\"=C...|               0/0|         1.0| 1173657600|    NOT A DATA CABLE|this is NOT a DAT...|\n",
      "|               43|USB Data Cable fo...|      unknown|          343|   David M. Cantrell|               0/0|         4.0| 1171584000|   works as expected|There's not much ...|\n",
      "|               43|USB Data Cable fo...|      unknown|          283|       J. S. Gaviota|               0/0|         5.0| 1142467200|  Excellent product!|I have a Sony Eri...|\n",
      "|               43|USB Data Cable fo...|      unknown|          779|\"Parathalyn \"\"Par...|               0/0|         1.0| 1133654400|Beware 3rd Party ...|Well, it technica...|\n",
      "|               43|USB Data Cable fo...|      unknown|          503|             D. Cram|               1/2|         3.0| 1135814400|Undecided on prod...|I currently have ...|\n",
      "|               43|USB Data Cable fo...|      unknown|          658|\"Jonathan C. Phil...|              6/10|         4.0| 1126915200|  Good cable to have|This is a good ca...|\n",
      "|               43|USB Data Cable fo...|      unknown|          769|                Cole|               2/4|         1.0| 1149379200|Don't Take the Ch...|If you purchase t...|\n",
      "|               43|USB Data Cable fo...|      unknown|          196|\"J. Baker \"\"Sunny\"\"\"|               1/3|         5.0| 1134518400|A must have produ...|This cable saves ...|\n",
      "|               62|Motorola HT820 St...|      unknown|          155|Ivan Arturo Paiz ...|               2/2|         4.0| 1153872000|Great for mp3 pho...|A great device, I...|\n",
      "|               62|Motorola HT820 St...|      unknown|          951|        J. Tomlinson|               0/0|         5.0| 1345161600|       Gold Standard|I've gone through...|\n",
      "|               62|Motorola HT820 St...|      unknown|          158|\"John Anetrella \"...|               0/0|         5.0| 1316476800|           Old skewl|Review is a few y...|\n",
      "|               62|Motorola HT820 St...|      unknown|          442|\"JRod3737 \"\"jrod3...|               5/8|         1.0| 1158624000|       Does not work|According to the ...|\n",
      "|               62|Motorola HT820 St...|      unknown|          964|             unknown|               1/2|         3.0| 1232150400|IT WONT PAIR WITH...|IT PAIRED WTH MY ...|\n",
      "|               58|                null|      unknown|          493|Martha Berenice P...|               0/0|         5.0| 1154217600|QUESTIONS ABOUT T...|I would like to b...|\n",
      "|               42|Belkin Executive ...|      unknown|          502|\"Tim Tuohy \"\"Tp2e\"\"\"|               0/2|         5.0| 1183420800|Cool cover for De...|This leather cove...|\n",
      "|               50|Samsung T809 M620...|         6.75|          198|            L. Henry|               1/1|         5.0| 1212364800|         Great Buy!!|I thought this it...|\n",
      "+-----------------+--------------------+-------------+-------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.read.load('ratings.csv', format='csv', header=True, inferSchema=True)\n",
    "ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration with Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the possible ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct values of ratings:\n"
     ]
    },
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Unsupported class file major version 57'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: java.lang.IllegalArgumentException: Unsupported class file major version 57\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166)\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148)\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136)\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237)\n\tat org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49)\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517)\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500)\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134)\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134)\n\tat scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)\n\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)\n\tat scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500)\n\tat org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175)\n\tat org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238)\n\tat org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631)\n\tat org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355)\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307)\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306)\n\tat org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:162)\n\tat org.apache.spark.SparkContext.clean(SparkContext.scala:2326)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2100)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:567)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:830)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ef8526145509>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Distinct values of ratings:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'review/score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    814\u001b[0m         \"\"\"\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Unsupported class file major version 57'"
     ]
    }
   ],
   "source": [
    "print('Distinct values of ratings:')\n",
    "print(sorted(ratings.select('review/score').distinct().rdd.map(lambda r: r[0]).collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that with this command we catch some elements that are not ratings. We will drop them and convert the ratings later so that they can be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the minimum number of ratings per user and minimum number of ratings per product (for rated products)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Unsupported class file major version 57'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o234.collectToPython.\n: java.lang.IllegalArgumentException: Unsupported class file major version 57\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166)\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148)\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136)\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237)\n\tat org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49)\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517)\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500)\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134)\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134)\n\tat scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)\n\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)\n\tat scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500)\n\tat org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175)\n\tat org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238)\n\tat org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631)\n\tat org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355)\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307)\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306)\n\tat org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:162)\n\tat org.apache.spark.SparkContext.clean(SparkContext.scala:2326)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2100)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3263)\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3260)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3260)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:567)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:830)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a418caf5aa85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"review/userid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtmp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"product/title\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'For the users that rated products and the products that were rated:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Minimum number of ratings per user is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Minimum number of ratings per product is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mtoPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;31m# Below is toPandas without Arrow optimization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Unsupported class file major version 57'"
     ]
    }
   ],
   "source": [
    "tmp1 = ratings.groupBy(\"review/userid\").count().toPandas()['count'].min()\n",
    "tmp2 = ratings.groupBy(\"product/title\").count().toPandas()['count'].min()\n",
    "print('For the users that rated products and the products that were rated:')\n",
    "print('Minimum number of ratings per user is {}'.format(tmp1))\n",
    "print('Minimum number of ratings per product is {}'.format(tmp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the total number of users in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 9245 distinct users in the data sets\n"
     ]
    }
   ],
   "source": [
    "tmp3 = ratings.select('review/userid').distinct().count()\n",
    "print('We have a total of {} distinct users in the data set'.format(tmp3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the total number of products in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 976 distinct products in the data sets\n"
     ]
    }
   ],
   "source": [
    "tmp4 = ratings.select('product/productid').distinct().count()\n",
    "print('We have a total of {} distinct products in the data set'.format(tmp4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the unrated products?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List product that are not rated yet: \n",
      "+-----------------+--------------------+\n",
      "|product/productid|       product/title|\n",
      "+-----------------+--------------------+\n",
      "|              741|Mobile Action MA7...|\n",
      "|              741|Mobile Action MA7...|\n",
      "|              741|Mobile Action MA7...|\n",
      "|              372|USB Data Cable fo...|\n",
      "|              372|USB Data Cable fo...|\n",
      "|              372|USB Data Cable fo...|\n",
      "|              372|USB Data Cable fo...|\n",
      "|              372|USB Data Cable fo...|\n",
      "|              372|USB Data Cable fo...|\n",
      "|              372|USB Data Cable fo...|\n",
      "+-----------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We create a temp SQL table view for easier query:\n",
    "ratings.createOrReplaceTempView(\"ratings\")\n",
    "\n",
    "print('List of products that are not rated yet: ')\n",
    "\n",
    "# SQL query (NOTE: WHERE ... NOT IN ... == ... LEFT JOIN ... WHERE ... IS NULL)\n",
    "\n",
    "# Approach 1\n",
    "spark.sql(\n",
    "    \"SELECT `product/productid`, `product/title`\"\n",
    "    \"FROM ratings \"\n",
    ").show(10)\n",
    "\n",
    "# Approach 2\n",
    "# spark.sql(\n",
    "#     \"SELECT m.movieId, m.title \"\n",
    "#     \"FROM movies m LEFT JOIN ratings r ON m.movieId=r.movieId \"\n",
    "#     \"WHERE r.movieId IS NULL\"\n",
    "# ).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **_@TOMMY: can you display above only the unique products that are not rated please (only 1 line per product)? And the nb of unrated products. Thanks!_** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting relevant rating data as an RDD for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File location and type\n",
    "file_location = \"ratings.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "# CSV options\n",
    "infer_schema = \"false\"\n",
    "first_row_is_header = \"false\"\n",
    "delimiter = \",\"\n",
    "\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n",
    "\n",
    "rating_data = df.rdd\n",
    "\n",
    "header = rating_data.take(1)[0]\n",
    "\n",
    "rating_data = rating_data \\\n",
    "    .filter(lambda line: line!=header) \\\n",
    "    .map(lambda x: list(x))\\\n",
    "    .map(lambda x: (int(x[3]), int(x[0]), x[6].split('/')[0])) \\\n",
    "    .filter(lambda x: x[2]!=' and Roll!\"\"\"') \\\n",
    "    .filter(lambda x: x[2]!=' & Books\"\"\"') \\\n",
    "    .filter(lambda x: x[2]!=' etc.\"\"\"') \\\n",
    "    .filter(lambda x: x[2]!=' gadget guy\"\"\"') \\\n",
    "    .map(lambda x: (x[0], x[1], float(x[2])))\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our implemention of the ALS matrix factorization algorithm in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's write useful functions for ALS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def set_data_matrix(M, data_list):\n",
    "    for data in data_list:\n",
    "        M[data[0], data[1]] = data[2]\n",
    "    return M\n",
    "\n",
    "def update(i, mat, ratings): # i = x, mat = V if caculate U, rating is M.\n",
    "    uu = mat.shape[0]\n",
    "    ff = mat.shape[1]\n",
    "\n",
    "    XtX = mat.T * mat # projection matrix\n",
    "    Xty = mat.T * ratings[i, :].T\n",
    "\n",
    "    for j in range(ff):\n",
    "        XtX[j, j] += LAMBDA * uu\n",
    "\n",
    "    return np.linalg.solve(XtX, Xty)\n",
    "\n",
    "def rmse(R, ms, us):\n",
    "    diff = R - ms * us.T\n",
    "    return np.sqrt(np.sum(np.power(diff, 2)) / (M * U)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's initialize matrices and parameters for the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-init spark\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"PythonALS\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_list = rating_data.collect()\n",
    "\n",
    "LAMBDA = 0.01   # regularization\n",
    "\n",
    "U = len(pd.read_csv('ratings.csv')['product/productId'].unique()) # nb of items\n",
    "M = len(pd.read_csv('ratings.csv')['review/userId'].unique()) # nb of users\n",
    "F = 8 # latent vector    \n",
    "num_iters = 10\n",
    "partitions = 2\n",
    "\n",
    "R = np.full((M, U), 0, dtype=np.float64)\n",
    "R = matrix(set_data_matrix(R, rating_list)) # M\n",
    "\n",
    "users = matrix(np.full((M, F), 1.0)) # U users matrix\n",
    "product = matrix(np.full((U, F), 1.0)) # V product matrix\n",
    "\n",
    "Rb = sc.broadcast(R)\n",
    "users_b = sc.broadcast(users)\n",
    "product_b = sc.broadcast(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's run the algorithm itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R= [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [4. 2. 5. ... 0. 0. 0.]]:\n",
      "ms= [[2.25425806e-14 2.25425806e-14 2.25425806e-14 ... 2.25425806e-14\n",
      "  2.25425806e-14 2.25425806e-14]\n",
      " [1.27787654e-02 1.27787654e-02 1.27787654e-02 ... 1.27787654e-02\n",
      "  1.27787654e-02 1.27787654e-02]\n",
      " [2.29777572e-03 2.29777572e-03 2.29777572e-03 ... 2.29777572e-03\n",
      "  2.29777572e-03 2.29777572e-03]\n",
      " ...\n",
      " [4.59555144e-04 4.59555144e-04 4.59555144e-04 ... 4.59555144e-04\n",
      "  4.59555144e-04 4.59555144e-04]\n",
      " [1.13630378e-03 1.13630378e-03 1.13630378e-03 ... 1.13630378e-03\n",
      "  1.13630378e-03 1.13630378e-03]\n",
      " [4.22484105e-01 4.22484105e-01 4.22484105e-01 ... 4.22484105e-01\n",
      "  4.22484105e-01 4.22484105e-01]]:\n",
      "\n",
      "\n",
      "\n",
      "us= [[6.99674285e-03 6.99674285e-03 6.99674285e-03 ... 6.99674285e-03\n",
      "  6.99674285e-03 6.99674285e-03]\n",
      " [3.57073218e-03 3.57073218e-03 3.57073218e-03 ... 3.57073218e-03\n",
      "  3.57073218e-03 3.57073218e-03]\n",
      " [8.76647815e-03 8.76647815e-03 8.76647815e-03 ... 8.76647815e-03\n",
      "  8.76647815e-03 8.76647815e-03]\n",
      " ...\n",
      " [2.84053749e-18 2.84053749e-18 2.84053749e-18 ... 2.84053749e-18\n",
      "  2.84053749e-18 2.84053749e-18]\n",
      " [1.02440265e-35 1.02440265e-35 1.02440265e-35 ... 1.02440265e-35\n",
      "  1.02440265e-35 1.02440265e-35]\n",
      " [9.54049315e-25 9.54049315e-25 9.54049317e-25 ... 9.54049316e-25\n",
      "  9.54049317e-25 9.54049316e-25]]:\n",
      "RMSE=0.1216\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_iters):\n",
    "    users = sc.parallelize(range(M), partitions) \\\n",
    "           .map(lambda x: update(x, product_b.value, Rb.value)) \\\n",
    "           .collect() # U, x = row number\n",
    "    # collect() returns a list, so array ends up being\n",
    "    # a 3-d array, we take the first 2 dims for the matrix\n",
    "    users = matrix(np.array(users)[:, :, 0]) # U\n",
    "    users_b = sc.broadcast(users)\n",
    "\n",
    "    product = sc.parallelize(range(U), partitions) \\\n",
    "           .map(lambda x: update(x, users_b.value, Rb.value.T)) \\\n",
    "           .collect() # V, x = columns\n",
    "    product = matrix(np.array(product)[:, :, 0])\n",
    "    product_b = sc.broadcast(product)\n",
    "\n",
    "    error = rmse(R, users, product)\n",
    "\n",
    "#print(\"Iteration %d:\" % i)\n",
    "print(\"R = %s:\" % (str(R))) \n",
    "print('\\n')\n",
    "print(\"ms = %s:\" % (str(users)))   \n",
    "print('\\n')\n",
    "print(\"us = %s:\" % (str(product)))           \n",
    "#print(\"\\nRMSE: %5.4f\\n\" % error)\n",
    "print('\\n')\n",
    "print(\"RMSE = %.4f\" % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Our implemention of the eALS algorithm for fast matrix factorization in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's write the fuctions useful for eALS matric factorization. Pseudo-code (Java-like) was found in the paper mentionned in introduction to this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data_matrix(M, data_list):\n",
    "    for data in data_list:\n",
    "        M[data[0], data[1]] = data[2]\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_user(u, U, V, R, SU, SV):\n",
    "    itemList = nb_items\n",
    "    SU_bis = SU.value\n",
    "    SV_bis = SV.value\n",
    "\n",
    "    # prediction cache for the user\n",
    "    for i in range(itemList):\n",
    "        prediction_items[i] = U[u]@V[i];\n",
    "        rating_items[i] = R[u][i];\n",
    "        w_items[i] = W[u][i]\n",
    "\n",
    "    oldVector = R[u]\n",
    "    for f in range(factors):\n",
    "        numer = 0\n",
    "        denom = 0\n",
    "        \n",
    "        #O(K) complexity for the negative part\n",
    "        for k in range(factors):\n",
    "            if k != f:\n",
    "                numer -= U[u][ k] * SV_bis[f][k]\n",
    "        \n",
    "        #O(Nu) complexity for the positive part\n",
    "        for i in range(itemList):\n",
    "            prediction_items[i] -= U[u][f] * V[i][f]\n",
    "            numer +=  (w_items[i]*rating_items[i] - (w_items[i]-Wi[i]) * prediction_items[i]) * V[i][f]\n",
    "            denom += (w_items[i]-Wi[i]) * V[i][f] * V[i][f]\n",
    "        denom += SV_bis[f][f] + reg;\n",
    "\n",
    "        #Parameter Update\n",
    "        U[u][f] = numer / denom\n",
    "\n",
    "        #Update the prediction cache\n",
    "        for i in range(itemList):\n",
    "            prediction_items[i] += U[u][f] * V[i][f]\n",
    "\n",
    "    #Update the SU cache\n",
    "    for f in range(factors):\n",
    "        for k in range(factors):\n",
    "            val = SU_bis[f][k] - oldVector[f] * oldVector[k] + U[u][f] * U[u][k]\n",
    "            SU_bis[f][k] = val\n",
    "            SU_bis[k][f] = val\n",
    "    #SU = sc.broadcast(SU_bis)\n",
    "    return U[u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_item(i, V, U, R, SU, SV):\n",
    "    userList = nb_users\n",
    "    SU_bis = SU.value\n",
    "    SV_bis = SV.value\n",
    "\n",
    "    # prediction cache for the user\n",
    "    for u in range(userList):\n",
    "        prediction_users[u] = U[u]@V[i]\n",
    "        rating_users[u] = R[u][i]\n",
    "        w_users[u] = W[u][i]\n",
    "\n",
    "    oldVector = R[i]\n",
    "    for f in range(factors):\n",
    "        numer = 0\n",
    "        denom = 0\n",
    "        \n",
    "        #O(K) complexity for the negative part\n",
    "        for k in range(factors):\n",
    "            if k != f:\n",
    "                numer -= V[i][ k] * SU_bis[f][k]\n",
    "        \n",
    "\n",
    "        #O(Nu) complexity for the positive part\n",
    "        for u in range(userList):\n",
    "            prediction_users[u] -= U[u][f] * V[i][f]\n",
    "            numer +=  (w_users[u]*rating_users[u] - (w_users[i]-Wi[i]) * prediction_users[u]) * U[u][f]\n",
    "            denom += (w_users[i]-Wi[i]) * U[u][f] * U[u][f]\n",
    "        denom += SU_bis[f][f] + reg;\n",
    "\n",
    "        #Parameter Update\n",
    "        V[i][f] = numer / denom\n",
    "\n",
    "        #Update the prediction cache\n",
    "        for u in range(userList):\n",
    "            prediction_users[u] += U[u][f] * V[i][f]\n",
    "\n",
    "    #Update the SV cache\n",
    "    for f in range(factors):\n",
    "        for k in range(factors):\n",
    "            val = SV_bis[f][k] - oldVector[f] * oldVector[k] * Wi[i] + V[i][f]*V[i][k]*Wi[i]\n",
    "            SV_bis[f][k] = val\n",
    "            SV_bis[k][f]= val\n",
    "    #SV = sc.broadcast(SV_bis)\n",
    "        \n",
    "    return V[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's initialize the matrices and parameters we will need for eALS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-init spark\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"Python_eALS\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_list = rating_data.collect()\n",
    "\n",
    "partitions = 10\n",
    "\n",
    "# Set model priors:\n",
    "factors = 10 # number of latent factors.\n",
    "maxIter = 20 #maximum iterations.\n",
    "reg = 0.01 #regularization parameters\n",
    "init_mean = 0;  # Gaussian mean for init V\n",
    "init_stdev = 0.01 #Gaussian std-dev for init V\n",
    "nb_items = len(pd.read_csv('ratings.csv')['product/productId'].unique()) # items\n",
    "nb_users = len(pd.read_csv('ratings.csv')['review/userId'].unique()) # users\n",
    "\n",
    "R = np.full((nb_users, nb_items), 0, dtype=np.float64)\n",
    "R = matrix(set_data_matrix(R, rating_list)) # M\n",
    "R = np.array(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell assigns weights to implicit data (i.e. negative feedback),\n",
    "with a weighting strategy based on item popularity and described in the paper.\n",
    "\"\"\"\n",
    "\n",
    "# Set the Wi as a decay function w0 * pi ^ alpha\n",
    "w0 = 1\n",
    "s = 0 \n",
    "Z = 0\n",
    "alpha = 1\n",
    "p = [0 for i in range(nb_items)]\n",
    "\n",
    "for i in range(nb_items):\n",
    "    p[i] = sum(R[0]!=0) # Nb of items per user\n",
    "    s += p[i]\n",
    "# convert p[i] to probability \n",
    "for i in range(nb_items):\n",
    "    p[i] = p[i]/s;\n",
    "   # p[i] = p[i]**alpha;\n",
    "    Z += p[i];\n",
    "# Assign weight\n",
    "Wi = [0 for i in range(nb_items)];\n",
    "for i in range(nb_items):\n",
    "    Wi[i] = w0 * p[i] / Z;\n",
    "# By default, the weight for positive instances is uniformly 1.\n",
    "W = np.full((nb_users, nb_items), 0, dtype=np.float64)\n",
    "for u in range(nb_users):\n",
    "    for i in R[u]:\n",
    "        W[u][int(i)]= 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init caches\n",
    "prediction_users = [0 for i in range(nb_users)];\n",
    "prediction_items = [0 for i in range(nb_items)];\n",
    "rating_users = [0 for i in range(nb_users)];\n",
    "rating_items = [0 for i in range(nb_items)];\n",
    "w_users = [0 for i in range(nb_users)];\n",
    "w_items = [0 for i in range(nb_items)];\n",
    "\n",
    "# Init model parameters\n",
    "users = np.random.normal(init_mean, init_stdev, \n",
    "                         nb_users*factors).reshape((nb_users,factors)) # latent vectors for users\n",
    "product = np.random.normal(init_mean, init_stdev, \n",
    "                           nb_items*factors).reshape((nb_items, factors)) # latent vectors for items\n",
    "SU = users.T@users\n",
    "SV = np.full((factors, factors), 0, dtype=np.float64)\n",
    "\n",
    "for f in range(factors):\n",
    "    for k in range(factors):\n",
    "        val = 0;\n",
    "        for i in range(nb_items):\n",
    "            val += product[i][f] * product[i][k]* Wi[i]\n",
    "        SV[f][k] = val\n",
    "        SV[k][f] = val\n",
    "\n",
    "user_b = users\n",
    "product_b = product\n",
    "Rb = R\n",
    "SU = sc.broadcast(SU)\n",
    "SV = sc.broadcast(SV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run the eALS algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in range(maxIter):\n",
    "    users = sc.parallelize(range(nb_users), partitions) \\\n",
    "               .map(lambda u: update_user(u, user_b, product_b, Rb, SU, SV)) \\\n",
    "               .collect() #u user id, \n",
    "    users_b = users\n",
    "    \n",
    "    product = sc.parallelize(range(nb_items), partitions) \\\n",
    "               .map(lambda i: update_item(i, product_b, user_b, Rb, SU, SV)) \\\n",
    "               .collect() #V, x = columns\n",
    "    product_b = product    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12399402466204804"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rmse_bis(R, ms, us):\n",
    "    diff = R - ms@us.T\n",
    "    return np.sqrt(np.sum(np.power(diff, 2)) / (nb_users * nb_items))\n",
    "                   \n",
    "rmse_bis(R, np.matrix(users), np.matrix(product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that RMSE is roughly the same as with regular ALS, but an advantage of eALS is faster computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **_@TOMMY: if not too complicated, can you display computation time for eALS and ALS plz ? Thanks!_** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstruct ratings from reconstructed rating matrix table to compare with predicted ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_reconstructed = np.matrix(users)@np.matrix(product).T\n",
    "r = pd.DataFrame(columns=['item_id', 'user_id', 'rate'])\n",
    "\n",
    "for line in rating_list:\n",
    "    product_j = line[1]\n",
    "    user_i = line[0]\n",
    "    rate = float(R_reconstructed[user_i].reshape(R_reconstructed[product_j].shape[1],1)[product_j])\n",
    "    r = r.append(pd.DataFrame(np.array([[int(product_j), int(user_i), rate]]),\n",
    "                              columns=['item_id', 'user_id', 'rate']), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.rate = r.rate.apply(lambda x: round(x,1) if (x>0) else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS implementation using the existing PySpark library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender system with existing PySpark ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 3.120677240286891\n"
     ]
    }
   ],
   "source": [
    "ratings = spark.createDataFrame(rating_data)\n",
    "(train, test) = ratings.randomSplit([0.8, 0.2]) # train-test split\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "# Note that we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"_1\", itemCol=\"_2\", ratingCol=\"_3\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als.fit(train)\n",
    "\n",
    "# Evaluate the model by computing RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"_3\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 10 product recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "\n",
    "# Generate top 10 user recommendations for each product\n",
    "movieRecs = model.recommendForAllItems(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **_@TOMMY: can you print the top 10 product and user recommendations computed in the cell above plz ? Thanks!_** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS model evaluation and selection (grid search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cells, we write and run a grid search function to determine the best ALS matrix factorization model (in terms of nb of latent factors and regularization coefficient):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ALS(train_data, validation_data, num_iters, reg_param, ranks):\n",
    "    \"\"\"\n",
    "    Grid Search Function to select the best model based on RMSE of hold-out data\n",
    "    \"\"\"\n",
    "    # initial\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    for rank in ranks:\n",
    "        for reg in reg_param:\n",
    "            # train ALS model\n",
    "            als = ALS(maxIter=num_iters, regParam=reg, userCol=\"_1\", itemCol=\"_2\", ratingCol=\"_3\", \n",
    "                      coldStartStrategy=\"drop\")\n",
    "            model = als.fit(train)\n",
    "            # make prediction\n",
    "            predictions = model.transform(test)\n",
    "            evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"_3\",\n",
    "                                            predictionCol=\"prediction\")\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            print('{} latent factors and regularization = {}: validation RMSE is {}'.format(rank, reg, rmse))\n",
    "            if rmse < min_error:\n",
    "                min_error = rmse\n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "    print('\\nThe best model has {} latent factors and regularization = {}'.format(best_rank, best_regularization))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 latent factors and regularization = 0.001: validation RMSE is 3.3331102801915704\n",
      "8 latent factors and regularization = 0.01: validation RMSE is 2.9467707735746833\n",
      "8 latent factors and regularization = 0.05: validation RMSE is 2.816589387154773\n",
      "8 latent factors and regularization = 0.1: validation RMSE is 2.7352330477000217\n",
      "8 latent factors and regularization = 0.2: validation RMSE is 2.6822093319222815\n",
      "10 latent factors and regularization = 0.001: validation RMSE is 3.3331102801915704\n",
      "10 latent factors and regularization = 0.01: validation RMSE is 2.9467707735746833\n",
      "10 latent factors and regularization = 0.05: validation RMSE is 2.816589387154773\n",
      "10 latent factors and regularization = 0.1: validation RMSE is 2.7352330477000217\n",
      "10 latent factors and regularization = 0.2: validation RMSE is 2.6822093319222815\n",
      "12 latent factors and regularization = 0.001: validation RMSE is 3.3331102801915704\n",
      "12 latent factors and regularization = 0.01: validation RMSE is 2.9467707735746833\n",
      "12 latent factors and regularization = 0.05: validation RMSE is 2.816589387154773\n",
      "12 latent factors and regularization = 0.1: validation RMSE is 2.7352330477000217\n",
      "12 latent factors and regularization = 0.2: validation RMSE is 2.6822093319222815\n",
      "14 latent factors and regularization = 0.001: validation RMSE is 3.3331102801915704\n",
      "14 latent factors and regularization = 0.01: validation RMSE is 2.9467707735746833\n",
      "14 latent factors and regularization = 0.05: validation RMSE is 2.816589387154773\n",
      "14 latent factors and regularization = 0.1: validation RMSE is 2.7352330477000217\n",
      "14 latent factors and regularization = 0.2: validation RMSE is 2.6822093319222815\n",
      "16 latent factors and regularization = 0.001: validation RMSE is 3.3331102801915704\n",
      "16 latent factors and regularization = 0.01: validation RMSE is 2.9467707735746833\n",
      "16 latent factors and regularization = 0.05: validation RMSE is 2.816589387154773\n",
      "16 latent factors and regularization = 0.1: validation RMSE is 2.7352330477000217\n",
      "16 latent factors and regularization = 0.2: validation RMSE is 2.6822093319222815\n",
      "18 latent factors and regularization = 0.001: validation RMSE is 3.3331102801915704\n",
      "18 latent factors and regularization = 0.01: validation RMSE is 2.9467707735746833\n",
      "18 latent factors and regularization = 0.05: validation RMSE is 2.816589387154773\n",
      "18 latent factors and regularization = 0.1: validation RMSE is 2.7352330477000217\n",
      "18 latent factors and regularization = 0.2: validation RMSE is 2.6822093319222815\n",
      "20 latent factors and regularization = 0.001: validation RMSE is 3.3331102801915704\n",
      "20 latent factors and regularization = 0.01: validation RMSE is 2.9467707735746833\n",
      "20 latent factors and regularization = 0.05: validation RMSE is 2.816589387154773\n",
      "20 latent factors and regularization = 0.1: validation RMSE is 2.7352330477000217\n",
      "20 latent factors and regularization = 0.2: validation RMSE is 2.6822093319222815\n",
      "\n",
      "The best model has 8 latent factors and regularization = 0.2\n",
      "Total Runtime: 298.50 seconds\n"
     ]
    }
   ],
   "source": [
    "# hyper-param config\n",
    "num_iterations = 10\n",
    "ranks = [8, 10, 12, 14, 16, 18, 20]\n",
    "reg_params = [0.001, 0.01, 0.05, 0.1, 0.2]\n",
    "\n",
    "# grid search and select best model\n",
    "start_time = time.time()\n",
    "final_model = train_ALS(train, test, num_iterations, reg_params, ranks)\n",
    "\n",
    "print ('Total Runtime: {:.2f} seconds'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS model learning curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last step in our project, let's plot the learning curve of the Spark ALS model (with the best parameters selected by grid search) compared to the number of iterations over our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(arr_iters, train_data, validation_data, reg, rank):\n",
    "    \"\"\"\n",
    "    Plot function to show learning curve of ALS\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    for num_iters in arr_iters:\n",
    "        # train ALS model\n",
    "        als = ALS(maxIter=num_iters, regParam=reg, userCol=\"_1\", itemCol=\"_2\", ratingCol=\"_3\", \n",
    "                  coldStartStrategy=\"drop\")\n",
    "        model = als.fit(train)\n",
    "        # make prediction\n",
    "        predictions = model.transform(test)\n",
    "        evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"_3\", predictionCol=\"prediction\")\n",
    "        rmse = evaluator.evaluate(predictions)\n",
    "        errors.append(rmse)\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(arr_iters, errors)\n",
    "    plt.xlabel('number of iterations')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title('ALS Learning Curve')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create an array of num_iters\n",
    "iter_array = list(range(1, 11))\n",
    "\n",
    "# create learning curve plot\n",
    "plot_learning_curve(iter_array, train, test, 0.05, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **_@TOMMY: for the graph above, you use lambda=0.05 and rank=20. Shouldn't we do it rather with the best parameters found in grid search (i.e. 0.2 and 8)?_** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally let's evaluate the final model by computing the RMSE on our test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 2.6822093319222815\n"
     ]
    }
   ],
   "source": [
    "predictions = final_model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"_3\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **_@TOMMY: maybe add here a short final conclusion, just comparing this model with the previous ones, and concluding the project. After that I think we're done, it's great!! Bravo amigo!_** </font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
